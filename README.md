# ðŸ§¹ Superstore Data Cleaning Project

## ðŸ“Œ Project Overview  
This project demonstrates a **step-by-step data cleaning workflow** applied to the popular *Superstore* dataset. The goal is to transform the raw data into a clean, analysis-ready version, while documenting every step for transparency and reproducibility.  

---

## ðŸ“‚ Files in This Repo
- **`superstore_raw.xls`** â†’ Original dataset (uncleaned).  
- **`superstore_cleaned.xls`** â†’ Fully cleaned dataset after Block 4.  
- **`data_documentation.xls`** â†’ Detailed log of all cleaning steps (Block 1â€“4).  

---

## ðŸ›  Cleaning Workflow
The cleaning process was structured into **4 Blocks**, with each committed separately to GitHub for version control.

### ðŸ”¹ Block 1: Column & Text Cleanup
- Renamed headers to lowercase + underscores  
- Trimmed text fields (`TRIM`)  
- Checked missing values (`COUNTBLANK`)  
- Standardized date formats to `YYYY-MM-DD`

### ðŸ”¹ Block 2: Duplicate Validation
- Verified `row_id` uniqueness  
- Confirmed `order_id` repetition expected (across multiple products)  

### ðŸ”¹ Block 3: Data Types & Numeric Standards
- Converted IDs and postal codes to **Text**  
- Standardized numeric fields:  
  - `sales`, `profit`, `discount` â†’ 2 decimals  
  - `quantity` â†’ integer  
- Ensured categorical fields stored as Text  

### ðŸ”¹ Block 4: Categorical Standardization & Validation
- Converted categorical values (`region`, `segment`, `category`, `sub_category`, `state`, `city`) to lowercase  
- Extracted unique values for validation  
- Validated `state` against U.S. reference list (50 states + DC)  
- Reviewed city anomalies:  
  - `new york city` consistently used (no `new york`)  
  - All `saint` values fully spelled (no abbreviations)  
  - `port saint lucie` verified as an official city name  

---

## âœ… Final Deliverables
- A fully cleaned dataset: **`superstore_cleaned.xlsx`**  
- A transparent step-by-step **documentation log** (`data_documentation.xlsx`)   
